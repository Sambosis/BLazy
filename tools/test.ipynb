{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_context_manager import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_context_manager import CodeContextManager\n",
    "from code_context_manager import CodeFile\n",
    "# Initialize with persistence file\n",
    "manager = CodeContextManager(\"code_context.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"test_form.py\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "manager.update_file(\n",
    "    name=\"test_form.py\",\n",
    "    content=content,\n",
    "    dependencies={},\n",
    "    description=\"A simple module\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# walk the directory and add all the python files to the context\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".py\"):\n",
    "            with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                manager.update_file(name=file, content=content, dependencies={}, description=\"A simple module\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the code is valid\n",
    "print(manager.is_code_valid(content))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in manager.files :\n",
    "    # get a the python code from the text from the ``python code`` block\n",
    "    rr(file)\n",
    "    # find the first ``python code`` block\n",
    "    # rr(code_text)\n",
    "\n",
    "    # rr(manager.is_code_valid(code_text))\n",
    "    rr(code_text)\n",
    "    # rr(f\"{file[name]}: {is_valid}\")\n",
    "    rr(\"-\"*110)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in manager.get_context_messages():\n",
    "    # get a the python code from the text from the ``python code`` block\n",
    "    code_text = file[\"content\"][0][\"text\"]\n",
    "    # find the first ``python code`` block\n",
    "    # rr(code_text)\n",
    "    code_start = code_text.find(\"```python\")\n",
    "    rr(code_start)\n",
    "    code_end = code_text[code_start+9:].find(\"```\")\n",
    "    rr(code_end)\n",
    "    code_text = code_text[code_start+9:code_start+code_end+8]\n",
    "    # rr(code_context_manager.is_code_valid(code_text))\n",
    "    # rr(code_text)\n",
    "    rr(manager.extract_dependencies(code_text))\n",
    "    # rr(f\"{file[name]}: {is_valid}\")\n",
    "    rr(\"-\"*110)\n",
    "# print(code_context_manager.is_code_valid(manager.files[file][\"content\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DEF_PREFIXES = ['def ' , 'async def ']\n",
    "NEWLINE = '\\n'\n",
    "\n",
    "def get_function_name(code):\n",
    "    \"\"\"\n",
    "    Extract function name from a line beginning with def or async def.\n",
    "    \"\"\"\n",
    "    for prefix in DEF_PREFIXES:\n",
    "        if code.startswith(prefix):\n",
    "            return code[len(prefix): code.index('(')]\n",
    "\n",
    "\n",
    "def get_until_no_space(all_lines, i):\n",
    "    \"\"\"\n",
    "    Get all lines until a line outside the function definition is found.\n",
    "    \"\"\"\n",
    "    ret = [all_lines[i]]\n",
    "    for j in range(i + 1, len(all_lines)):\n",
    "        if len(all_lines[j]) == 0 or all_lines[j][0] in [' ', '\\t']:\n",
    "            ret.append(all_lines[j])\n",
    "        else:\n",
    "            break\n",
    "    return NEWLINE.join(ret)\n",
    "\n",
    "\n",
    "def get_functions(filepath):\n",
    "    \"\"\"\n",
    "    Get all functions in a Python file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        all_lines = file.read().replace('\\r', NEWLINE).split(NEWLINE)\n",
    "        for i, l in enumerate(all_lines):\n",
    "            for prefix in DEF_PREFIXES:\n",
    "                if l.startswith(prefix):\n",
    "                    code = get_until_no_space(all_lines, i)\n",
    "                    function_name = get_function_name(code)\n",
    "                    yield {\n",
    "                        code: code,\n",
    "                        function_name: function_name,\n",
    "                        filepath: filepath,\n",
    "                    }\n",
    "                    break\n",
    "\n",
    "\n",
    "def extract_functions_from_repo(code_root):\n",
    "    \"\"\"\n",
    "    Extract all .py functions from the repository.\n",
    "    \"\"\"\n",
    "    code_files = list(code_root.glob(\"**/*.py\"))\n",
    "\n",
    "    num_files = len(code_files)\n",
    "    print(f\"Total number of .py files: {num_files}\")\n",
    "\n",
    "    if num_files == 0:\n",
    "        print(\"Verify openai-python repo exists and code_root is set correctly.\")\n",
    "        return None\n",
    "\n",
    "    all_funcs = [\n",
    "        func\n",
    "        for code_file in code_files\n",
    "        for func in get_functions(str(code_file))\n",
    "    ]\n",
    "\n",
    "    num_funcs = len(all_funcs)\n",
    "    print(f\"Total number of functions extracted: {num_funcs}\")\n",
    "\n",
    "    return all_funcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set user root directory to the openai-python repository\n",
    "root_dir = Path.cwd()\n",
    "\n",
    "# Assumes the openai-python repository exists in the users root directory\n",
    "code_root = root_dir \n",
    "rr(code_root)\n",
    "# Extract all functions from the repository\n",
    "all_funcs = extract_functions_from_repo(code_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.update_file(\n",
    "    name=\"test_form.py\",\n",
    "    content=content,\n",
    "    dependencies={},\n",
    "    description=\"A simple module\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_funcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for func in all_funcs:\n",
    "    # manager.update_file(\n",
    "    #     name=func[\"filepath\"],\n",
    "    #     content=func[\"code\"],\n",
    "    #     dependencies={},\n",
    "    #     description=func[\"function_name\"]\n",
    "    # )\n",
    "    rr(func[\"filepath\"])\n",
    "    # rr(type(func[\"function_name\"]))\n",
    "    # rr(type(func[\"code\"]))\n",
    "    # rr(\"-\"*110)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ast\n",
    "import inspect\n",
    "\n",
    "class FunctionInfo(BaseModel):\n",
    "    code: str\n",
    "    function_name: str\n",
    "    filepath: str\n",
    "    docstring: Optional[str] = None\n",
    "    args: List[str] = Field(default_factory=list)\n",
    "    return_annotation: Optional[str] = None\n",
    "\n",
    "class FileInfo(BaseModel):\n",
    "    path: Path\n",
    "    functions: List[FunctionInfo] = Field(default_factory=list)\n",
    "\n",
    "class CodeAnalyzer(BaseModel):\n",
    "    code_root: Path\n",
    "    def_prefixes: List[str] = Field(default=['def ' , 'async def '])\n",
    "    newline: str = Field(default='\\n')\n",
    "    files: List[FileInfo] = Field(default_factory=list)\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def extract_function_details(self, code: str) -> dict:\n",
    "        \"\"\"\n",
    "        Extract function details including docstring using AST\n",
    "        \"\"\"\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    # Get docstring\n",
    "                    docstring = ast.get_docstring(node)\n",
    "                    \n",
    "                    # Get arguments\n",
    "                    args = []\n",
    "                    for arg in node.args.args:\n",
    "                        args.append(arg.arg)\n",
    "                    \n",
    "                    # Get return annotation if it exists\n",
    "                    return_annotation = None\n",
    "                    if node.returns:\n",
    "                        return_annotation = ast.unparse(node.returns)\n",
    "                    \n",
    "                    return {\n",
    "                        \"docstring\": docstring,\n",
    "                        \"args\": args,\n",
    "                        \"return_annotation\": return_annotation\n",
    "                    }\n",
    "        except SyntaxError:\n",
    "            # Handle cases where the code snippet might be incomplete\n",
    "            return {\"docstring\": None, \"args\": [], \"return_annotation\": None}\n",
    "        \n",
    "        return {\"docstring\": None, \"args\": [], \"return_annotation\": None}\n",
    "\n",
    "    def get_function_name(self, code: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract function name from a line beginning with def or async def.\n",
    "        \"\"\"\n",
    "        for prefix in self.def_prefixes:\n",
    "            if code.startswith(prefix):\n",
    "                return code[len(prefix): code.index('(')]\n",
    "        return None\n",
    "\n",
    "    def get_until_no_space(self, all_lines: List[str], i: int) -> str:\n",
    "        \"\"\"\n",
    "        Get all lines until a line outside the function definition is found.\n",
    "        \"\"\"\n",
    "        ret = [all_lines[i]]\n",
    "        indent_level = len(all_lines[i]) - len(all_lines[i].lstrip())\n",
    "        \n",
    "        for j in range(i + 1, len(all_lines)):\n",
    "            line = all_lines[j]\n",
    "            if not line.strip():  # Empty line\n",
    "                ret.append(line)\n",
    "                continue\n",
    "                \n",
    "            current_indent = len(line) - len(line.lstrip())\n",
    "            if current_indent <= indent_level and line.strip():\n",
    "                break\n",
    "                \n",
    "            ret.append(line)\n",
    "            \n",
    "        return self.newline.join(ret)\n",
    "\n",
    "    def get_functions(self, filepath: str) -> List[FunctionInfo]:\n",
    "        \"\"\"\n",
    "        Get all functions in a Python file.\n",
    "        \"\"\"\n",
    "        with open(filepath, 'r') as file:\n",
    "            all_lines = file.read().replace('\\r', self.newline).split(self.newline)\n",
    "            functions = []\n",
    "            i = 0\n",
    "            while i < len(all_lines):\n",
    "                line = all_lines[i]\n",
    "                for prefix in self.def_prefixes:\n",
    "                    if line.strip().startswith(prefix):\n",
    "                        code = self.get_until_no_space(all_lines, i)\n",
    "                        function_name = self.get_function_name(code)\n",
    "                        if function_name:\n",
    "                            # Extract additional details using AST\n",
    "                            details = self.extract_function_details(code)\n",
    "                            \n",
    "                            functions.append(\n",
    "                                FunctionInfo(\n",
    "                                    code=code,\n",
    "                                    function_name=function_name,\n",
    "                                    filepath=filepath,\n",
    "                                    docstring=details[\"docstring\"],\n",
    "                                    args=details[\"args\"],\n",
    "                                    return_annotation=details[\"return_annotation\"]\n",
    "                                )\n",
    "                            )\n",
    "                        break\n",
    "                i += 1\n",
    "        return functions\n",
    "\n",
    "    def analyze_repo(self) -> List[FileInfo]:\n",
    "        \"\"\"\n",
    "        Extract all .py functions from the repository and return them as FileInfo objects.\n",
    "        \"\"\"\n",
    "        code_files = list(self.code_root.glob(\"**/*.py\"))\n",
    "\n",
    "        num_files = len(code_files)\n",
    "        print(f\"Total number of .py files: {num_files}\")\n",
    "\n",
    "        if num_files == 0:\n",
    "            print(\"Verify the repository exists and code_root is set correctly.\")\n",
    "            return []\n",
    "\n",
    "        self.files = []\n",
    "        for code_file in code_files:\n",
    "            file_info = FileInfo(\n",
    "                path=code_file,\n",
    "                functions=self.get_functions(str(code_file))\n",
    "            )\n",
    "            self.files.append(file_info)\n",
    "\n",
    "        num_funcs = sum(len(file.functions) for file in self.files)\n",
    "        print(f\"Total number of functions extracted: {num_funcs}\")\n",
    "\n",
    "        return self.files\n",
    "\n",
    "    def get_function_dict(self) -> Dict[str, List[FunctionInfo]]:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of filename to list of functions\n",
    "        \"\"\"\n",
    "        return {str(file.path): file.functions for file in self.files}\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the analyzed data to a pandas DataFrame\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for file in self.files:\n",
    "            for func in file.functions:\n",
    "                rows.append({\n",
    "                    filepath: func.filepath,\n",
    "                    function_name: func.function_name,\n",
    "                    code: func.code,\n",
    "                    docstring: func.docstring,\n",
    "                    args: func.args,\n",
    "                    return_annotation: func.return_annotation\n",
    "                })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def get_functions_with_docstrings(self) -> List[FunctionInfo]:\n",
    "        \"\"\"\n",
    "        Returns only functions that have docstrings\n",
    "        \"\"\"\n",
    "        return [\n",
    "            func \n",
    "            for file in self.files \n",
    "            for func in file.functions \n",
    "            if func.docstring\n",
    "        ]\n",
    "\n",
    "    def get_functions_missing_docstrings(self) -> List[FunctionInfo]:\n",
    "        \"\"\"\n",
    "        Returns functions that are missing docstrings\n",
    "        \"\"\"\n",
    "        return [\n",
    "            func \n",
    "            for file in self.files \n",
    "            for func in file.functions \n",
    "            if not func.docstring\n",
    "        ]\n",
    "\n",
    "    def get_docstring_coverage_stats(self) -> dict:\n",
    "        \"\"\"\n",
    "        Returns statistics about docstring coverage\n",
    "        \"\"\"\n",
    "        total_functions = sum(len(file.functions) for file in self.files)\n",
    "        with_docstrings = len(self.get_functions_with_docstrings())\n",
    "        without_docstrings = len(self.get_functions_missing_docstrings())\n",
    "        \n",
    "        return {\n",
    "            \"total_functions\": total_functions,\n",
    "            \"with_docstrings\": with_docstrings,\n",
    "            \"without_docstrings\": without_docstrings,\n",
    "            \"coverage_percentage\": (with_docstrings / total_functions * 100) if total_functions > 0 else 0\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the analyzer\n",
    "# Set user root directory to the openai-python repository\n",
    "root_dir = Path.cwd()\n",
    "\n",
    "# Assumes the openai-python repository exists in the users root directory\n",
    "code_root = root_dir \n",
    "analyzer = CodeAnalyzer(code_root=code_root,    def_prefixes=[def , async def , cdef , class ],  # Custom prefixes\n",
    ")\n",
    "\n",
    "# Analyze the repository\n",
    "analyzer.analyze_repo()\n",
    "\n",
    "# Get results in different formats\n",
    "df = analyzer.to_dataframe()  # As DataFrame\n",
    "function_dict = analyzer.get_function_dict()  # As Dictionary\n",
    "\n",
    "\n",
    "# Access the files directly\n",
    "for file_info in analyzer.files:\n",
    "    print(f\"File: {file_info.path}\")\n",
    "    for function in file_info.functions:\n",
    "        print(f\"  Function: {function.function_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr(analyzer.get_functions_missing_docstrings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and analyze\n",
    "# analyzer = CodeAnalyzer(code_root=code_root)\n",
    "analyzer.analyze_repo()\n",
    "\n",
    "# Get all functions with docstrings\n",
    "documented_functions = analyzer.get_functions_with_docstrings()\n",
    "\n",
    "# Get coverage statistics\n",
    "coverage_stats = analyzer.get_docstring_coverage_stats()\n",
    "print(f\"Docstring coverage: {coverage_stats[coverage_percentage]:.2f}%\")\n",
    "\n",
    "# Get detailed DataFrame\n",
    "df = analyzer.to_dataframe()\n",
    "print(\"\\nFunctions with their docstrings:\")\n",
    "print(df[[function_name, docstring, args, return_annotation]])\n",
    "\n",
    "# Find functions missing docstrings\n",
    "missing_docs = analyzer.get_functions_missing_docstrings()\n",
    "print(\"\\nFunctions missing docstrings:\")\n",
    "for func in missing_docs:\n",
    "    print(f\"- {func.function_name} in {func.filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyzer.to_dataframe()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Set\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ast\n",
    "from dataclasses import dataclass\n",
    "import networkx as nx\n",
    "import importlib\n",
    "import importlib.metadata\n",
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "from importlib.metadata import distributions, version, PackageNotFoundError\n",
    "\n",
    "def get_stdlib_modules() -> Set[str]:\n",
    "    \"\"\"Get a set of standard library module names\"\"\"\n",
    "    stdlib_paths = {\n",
    "        os.path.dirname(os.__file__),  # Standard library path\n",
    "        os.path.dirname(importlib.__file__),  # Additional standard library path\n",
    "    }\n",
    "    \n",
    "    stdlib_modules = set()\n",
    "    for path in stdlib_paths:\n",
    "        if os.path.exists(path):\n",
    "            for item in os.listdir(path):\n",
    "                name, ext = os.path.splitext(item)\n",
    "                if ext in {'.py', '.pyc'}:\n",
    "                    stdlib_modules.add(name)\n",
    "    \n",
    "    return stdlib_modules\n",
    "\n",
    "class DependencyInfo(BaseModel):\n",
    "    name: str\n",
    "    version: Optional[str] = None\n",
    "    is_standard_lib: bool = False\n",
    "    is_local: bool = False\n",
    "\n",
    "    @classmethod\n",
    "    def from_import(cls, module_name: str, code_root: Path) -> \"DependencyInfo\":\n",
    "        \"\"\"Create DependencyInfo from a module name\"\"\"\n",
    "        root_module = module_name.split('.')[0]\n",
    "        \n",
    "        # Check if its a standard library module\n",
    "        if root_module in get_stdlib_modules():\n",
    "            return cls(\n",
    "                name=root_module,\n",
    "                is_standard_lib=True\n",
    "            )\n",
    "        \n",
    "        # Check if its a local module\n",
    "        local_module_path = code_root / f\"{root_module}.py\"\n",
    "        if local_module_path.exists():\n",
    "            return cls(\n",
    "                name=root_module,\n",
    "                is_local=True\n",
    "            )\n",
    "        \n",
    "        # Must be an external dependency\n",
    "        try:\n",
    "            dep_version = version(root_module)\n",
    "            return cls(\n",
    "                name=root_module,\n",
    "                version=dep_version\n",
    "            )\n",
    "        except PackageNotFoundError:\n",
    "            return cls(name=root_module)\n",
    "\n",
    "\n",
    "class ArgumentInfo(BaseModel):\n",
    "    name: str\n",
    "    type_annotation: Optional[str] = None\n",
    "    default_value: Optional[str] = None\n",
    "\n",
    "class MethodInfo(BaseModel):\n",
    "    name: str\n",
    "    code: str\n",
    "    docstring: Optional[str] = None\n",
    "    args: List[ArgumentInfo] = Field(default_factory=list)\n",
    "    return_annotation: Optional[str] = None\n",
    "    decorators: List[str] = Field(default_factory=list)\n",
    "    is_property: bool = False\n",
    "    is_classmethod: bool = False\n",
    "    is_staticmethod: bool = False\n",
    "\n",
    "class ClassInfo(BaseModel):\n",
    "    name: str\n",
    "    code: str\n",
    "    docstring: Optional[str] = None\n",
    "    methods: List[MethodInfo] = Field(default_factory=list)\n",
    "    base_classes: List[str] = Field(default_factory=list)\n",
    "    filepath: str\n",
    "    class_variables: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "class ImportInfo(BaseModel):\n",
    "    module_name: str\n",
    "    imported_names: List[str] = Field(default_factory=list)\n",
    "    is_from_import: bool = False\n",
    "    alias: Optional[str] = None\n",
    "\n",
    "\n",
    "class FunctionInfo(BaseModel):\n",
    "    code: str\n",
    "    function_name: str\n",
    "    filepath: str\n",
    "    docstring: Optional[str] = None\n",
    "    args: List[ArgumentInfo] = Field(default_factory=list)\n",
    "    return_annotation: Optional[str] = None\n",
    "    decorators: List[str] = Field(default_factory=list)\n",
    "\n",
    "class FileInfo(BaseModel):\n",
    "    path: Path\n",
    "    functions: List[FunctionInfo] = Field(default_factory=list)\n",
    "    classes: List[ClassInfo] = Field(default_factory=list)\n",
    "    imports: List[ImportInfo] = Field(default_factory=list)\n",
    "    dependencies: List[DependencyInfo] = Field(default_factory=list)\n",
    "\n",
    "class CodeAnalyzer(BaseModel):\n",
    "    code_root: Path\n",
    "    def_prefixes: List[str] = Field(default=['def ' , 'async def '])\n",
    "    newline: str = Field(default='\\n')\n",
    "    files: List[FileInfo] = Field(default_factory=list)\n",
    "    dependency_graph: Optional[nx.DiGraph] = None\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def _parse_argument(self, arg: ast.arg, default=None) -> ArgumentInfo:\n",
    "        \"\"\"Parse function/method argument information\"\"\"\n",
    "        return ArgumentInfo(\n",
    "            name=arg.arg,\n",
    "            type_annotation=ast.unparse(arg.annotation) if arg.annotation else None,\n",
    "            default_value=ast.unparse(default) if default else None\n",
    "        )\n",
    "\n",
    "    def _extract_decorators(self, node: ast.FunctionDef) -> List[str]:\n",
    "        \"\"\"Extract decorator information from a function/method node\"\"\"\n",
    "        return [ast.unparse(decorator) for decorator in node.decorator_list]\n",
    "\n",
    "    def _is_special_method(self, decorator_list: List[str]) -> tuple:\n",
    "        \"\"\"Determine if method has special decorators\"\"\"\n",
    "        is_property = any(property in d for d in decorator_list)\n",
    "        is_classmethod = any(classmethod in d for d in decorator_list)\n",
    "        is_staticmethod = any(staticmethod in d for d in decorator_list)\n",
    "        return is_property, is_classmethod, is_staticmethod\n",
    "\n",
    "    def _extract_class_info(self, node: ast.ClassDef, code: str, filepath: str) -> ClassInfo:\n",
    "        \"\"\"Extract information about a class\"\"\"\n",
    "        methods = []\n",
    "        class_variables = {}\n",
    "        \n",
    "        # Get base classes\n",
    "        base_classes = [ast.unparse(base) for base in node.bases]\n",
    "        \n",
    "        for body_item in node.body:\n",
    "            if isinstance(body_item, ast.FunctionDef):\n",
    "                method_code = ast.unparse(body_item)\n",
    "                decorators = self._extract_decorators(body_item)\n",
    "                is_property, is_classmethod, is_staticmethod = self._is_special_method(decorators)\n",
    "                \n",
    "                # Parse arguments\n",
    "                args = []\n",
    "                for i, arg in enumerate(body_item.args.args[1:] if not is_staticmethod else body_item.args.args):\n",
    "                    default = body_item.args.defaults[i] if i < len(body_item.args.defaults) else None\n",
    "                    args.append(self._parse_argument(arg, default))\n",
    "\n",
    "                methods.append(MethodInfo(\n",
    "                    name=body_item.name,\n",
    "                    code=method_code,\n",
    "                    docstring=ast.get_docstring(body_item),\n",
    "                    args=args,\n",
    "                    return_annotation=ast.unparse(body_item.returns) if body_item.returns else None,\n",
    "                    decorators=decorators,\n",
    "                    is_property=is_property,\n",
    "                    is_classmethod=is_classmethod,\n",
    "                    is_staticmethod=is_staticmethod\n",
    "                ))\n",
    "            elif isinstance(body_item, ast.AnnAssign):\n",
    "                # Class variable with type annotation\n",
    "                class_variables[ast.unparse(body_item.target)] = ast.unparse(body_item.annotation)\n",
    "            elif isinstance(body_item, ast.Assign):\n",
    "                # Class variable without type annotation\n",
    "                for target in body_item.targets:\n",
    "                    class_variables[ast.unparse(target)] = None\n",
    "\n",
    "        return ClassInfo(\n",
    "            name=node.name,\n",
    "            code=ast.unparse(node),\n",
    "            docstring=ast.get_docstring(node),\n",
    "            methods=methods,\n",
    "            base_classes=base_classes,\n",
    "            filepath=filepath,\n",
    "            class_variables=class_variables\n",
    "        )\n",
    "\n",
    "    def _extract_imports(self, node: ast.Module) -> List[ImportInfo]:\n",
    "        \"\"\"Extract import information from a module\"\"\"\n",
    "        imports = []\n",
    "        for node_item in node.body:\n",
    "            if isinstance(node_item, ast.Import):\n",
    "                for name in node_item.names:\n",
    "                    imports.append(ImportInfo(\n",
    "                        module_name=name.name,\n",
    "                        alias=name.asname,\n",
    "                        imported_names=[]\n",
    "                    ))\n",
    "            elif isinstance(node_item, ast.ImportFrom):\n",
    "                if node_item.module:\n",
    "                    imports.append(ImportInfo(\n",
    "                        module_name=node_item.module,\n",
    "                        imported_names=[name.name for name in node_item.names],\n",
    "                        is_from_import=True,\n",
    "                        alias=None\n",
    "                    ))\n",
    "        return imports\n",
    "\n",
    "    def _analyze_dependencies(self, imports: List[ImportInfo]) -> List[DependencyInfo]:\n",
    "        \"\"\"Analyze dependencies from imports\"\"\"\n",
    "        seen_modules = set()\n",
    "        dependencies = []\n",
    "        \n",
    "        for imp in imports:\n",
    "            module_name = imp.module_name\n",
    "            if module_name in seen_modules:\n",
    "                continue\n",
    "                \n",
    "            seen_modules.add(module_name)\n",
    "            dependencies.append(\n",
    "                DependencyInfo.from_import(module_name, self.code_root)\n",
    "            )\n",
    "        \n",
    "        return dependencies\n",
    "    def analyze_file(self, filepath: str) -> FileInfo:\n",
    "        \"\"\"Analyze a single Python file\"\"\"\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "        try:\n",
    "            tree = ast.parse(content)\n",
    "            \n",
    "            functions = []\n",
    "            classes = []\n",
    "            \n",
    "            # Extract imports first\n",
    "            imports = self._extract_imports(tree)\n",
    "            dependencies = self._analyze_dependencies(imports)\n",
    "            \n",
    "            # Handle top-level nodes\n",
    "            for node in tree.body:\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    functions.append(self._extract_function_info(node, filepath))\n",
    "                elif isinstance(node, ast.ClassDef):\n",
    "                    classes.append(self._extract_class_info(node, content, filepath))\n",
    "                    \n",
    "            return FileInfo(\n",
    "                path=Path(filepath),\n",
    "                functions=functions,\n",
    "                classes=classes,\n",
    "                imports=imports,\n",
    "                dependencies=dependencies\n",
    "            )\n",
    "        except SyntaxError:\n",
    "            print(f\"Syntax error in file: {filepath}\")\n",
    "            return FileInfo(path=Path(filepath))\n",
    "    def build_dependency_graph(self):\n",
    "        \"\"\"Build a dependency graph of the project\"\"\"\n",
    "        self.dependency_graph = nx.DiGraph()\n",
    "        \n",
    "        for file_info in self.files:\n",
    "            file_node = str(file_info.path)\n",
    "            self.dependency_graph.add_node(file_node)\n",
    "            \n",
    "            for dep in file_info.dependencies:\n",
    "                if dep.is_local:\n",
    "                    # Add edge for local dependencies\n",
    "                    dep_file = str(self.code_root / f\"{dep.name}.py\")\n",
    "                    self.dependency_graph.add_edge(file_node, dep_file)\n",
    "\n",
    "    def get_class_hierarchy(self) -> nx.DiGraph:\n",
    "        \"\"\"Build and return the class hierarchy graph\"\"\"\n",
    "        hierarchy = nx.DiGraph()\n",
    "        \n",
    "        for file_info in self.files:\n",
    "            for class_info in file_info.classes:\n",
    "                hierarchy.add_node(class_info.name)\n",
    "                for base in class_info.base_classes:\n",
    "                    hierarchy.add_edge(base, class_info.name)\n",
    "                    \n",
    "        return hierarchy\n",
    "\n",
    "    def get_dependency_cycles(self) -> List[List[str]]:\n",
    "        \"\"\"Find circular dependencies in the project\"\"\"\n",
    "        if not self.dependency_graph:\n",
    "            self.build_dependency_graph()\n",
    "        return list(nx.simple_cycles(self.dependency_graph))\n",
    "\n",
    "    def to_dataframe(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Convert the analyzed data to multiple DataFrames\"\"\"\n",
    "        try:\n",
    "            # Functions DataFrame\n",
    "            functions_data = [\n",
    "                {\n",
    "                    'filepath': func.filepath,\n",
    "                    'name': func.function_name,\n",
    "                    'docstring': func.docstring,\n",
    "                    'args': [arg.dict() for arg in func.args],\n",
    "                    'return_annotation': func.return_annotation,\n",
    "                    'decorators': func.decorators\n",
    "                }\n",
    "                for file in self.files\n",
    "                for func in file.functions\n",
    "            ]\n",
    "            \n",
    "            # Classes DataFrame\n",
    "            classes_data = [\n",
    "                {\n",
    "                    'filepath': cls.filepath,\n",
    "                    'name': cls.name,\n",
    "                    'docstring': cls.docstring,\n",
    "                    'methods_count': len(cls.methods),\n",
    "                    'base_classes': cls.base_classes,\n",
    "                    'variables_count': len(cls.class_variables),\n",
    "                    'methods': [method.name for method in cls.methods],\n",
    "                    'has_docstring': cls.docstring is not None\n",
    "                }\n",
    "                for file in self.files\n",
    "                for cls in file.classes\n",
    "            ]\n",
    "            \n",
    "            # Dependencies DataFrame\n",
    "            dependencies_data = [\n",
    "                {\n",
    "                    'filepath': str(file.path),\n",
    "                    'dependency': dep.name,\n",
    "                    'version': dep.version,\n",
    "                    'is_standard_lib': dep.is_standard_lib,\n",
    "                    'is_local': dep.is_local\n",
    "                }\n",
    "                for file in self.files\n",
    "                for dep in file.dependencies\n",
    "            ]\n",
    "\n",
    "            return {\n",
    "                'functions': pd.DataFrame(functions_data) if functions_data else pd.DataFrame(),\n",
    "                'classes': pd.DataFrame(classes_data) if classes_data else pd.DataFrame(),\n",
    "                'dependencies': pd.DataFrame(dependencies_data) if dependencies_data else pd.DataFrame()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating DataFrames: {str(e)}\")\n",
    "            return {\n",
    "                'functions': pd.DataFrame(),\n",
    "                'classes': pd.DataFrame(),\n",
    "                'dependencies': pd.DataFrame()\n",
    "            }\n",
    "    def _extract_function_info(self, node: ast.FunctionDef, filepath: str) -> FunctionInfo:\n",
    "        \"\"\"Extract information about a function\"\"\"\n",
    "        args = []\n",
    "        for i, arg in enumerate(node.args.args):\n",
    "            default = node.args.defaults[i] if i < len(node.args.defaults) else None\n",
    "            args.append(self._parse_argument(arg, default))\n",
    "\n",
    "        return FunctionInfo(\n",
    "            code=ast.unparse(node),\n",
    "            function_name=node.name,\n",
    "            filepath=filepath,\n",
    "            docstring=ast.get_docstring(node),\n",
    "            args=args,\n",
    "            return_annotation=ast.unparse(node.returns) if node.returns else None,\n",
    "            decorators=self._extract_decorators(node)\n",
    "        )\n",
    "\n",
    "    # def to_dataframe(self) -> pd.DataFrame:\n",
    "    #     \"\"\"\n",
    "    #     Convert the analyzed data to a pandas DataFrame\n",
    "    #     \"\"\"\n",
    "    #     rows = []\n",
    "    #     for file in self.files:\n",
    "    #         for func in file.functions:\n",
    "    #             rows.append({\n",
    "    #                 filepath: func.filepath,\n",
    "    #                 function_name: func.function_name,\n",
    "    #                 code: func.code,\n",
    "    #                 docstring: func.docstring,\n",
    "    #                 args: func.args,\n",
    "    #                 return_annotation: func.return_annotation\n",
    "    #             })\n",
    "    #     return pd.DataFrame(rows)\n",
    "    def analyze_repo(self) -> List[FileInfo]:\n",
    "        \"\"\"\n",
    "        Analyze all Python files in the repository.\n",
    "        Returns a list of FileInfo objects containing analysis results.\n",
    "        \"\"\"\n",
    "        code_files = list(self.code_root.glob(\"**/*.py\"))\n",
    "\n",
    "        num_files = len(code_files)\n",
    "        print(f\"Total number of .py files: {num_files}\")\n",
    "\n",
    "        if num_files == 0:\n",
    "            print(\"Verify the repository exists and code_root is set correctly.\")\n",
    "            return []\n",
    "\n",
    "        self.files = []\n",
    "        for code_file in code_files:\n",
    "            try:\n",
    "                file_info = self.analyze_file(str(code_file))\n",
    "                self.files.append(file_info)\n",
    "                print(f\"Analyzed: {code_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing {code_file}: {str(e)}\")\n",
    "\n",
    "        print(f\"\\nAnalysis complete:\")\n",
    "        print(f\"Files processed: {len(self.files)}\")\n",
    "        print(f\"Classes found: {sum(len(f.classes) for f in self.files)}\")\n",
    "        print(f\"Functions found: {sum(len(f.functions) for f in self.files)}\")\n",
    "\n",
    "        return self.files\n",
    "    def _extract_function_info(self, node: ast.FunctionDef, filepath: str) -> FunctionInfo:\n",
    "        \"\"\"Extract information about a function\"\"\"\n",
    "        args = []\n",
    "        for i, arg in enumerate(node.args.args):\n",
    "            default = node.args.defaults[i] if i < len(node.args.defaults) else None\n",
    "            args.append(self._parse_argument(arg, default))\n",
    "\n",
    "        return FunctionInfo(\n",
    "            code=ast.unparse(node),\n",
    "            function_name=node.name,\n",
    "            filepath=filepath,\n",
    "            docstring=ast.get_docstring(node),\n",
    "            args=args,\n",
    "            return_annotation=ast.unparse(node.returns) if node.returns else None,\n",
    "            decorators=self._extract_decorators(node)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of .py files: 14\n",
      "Error analyzing c:\\mygit\\compuse\\computer_use_demo\\tools\\base.py: 'in <string>' requires string as left operand, not type\n",
      "Error analyzing c:\\mygit\\compuse\\computer_use_demo\\tools\\bash.py: 1 validation error for ClassInfo\n",
      "class_variables.description\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_type\n",
      "Analyzed: c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_original.py\n",
      "Analyzed: c:\\mygit\\compuse\\computer_use_demo\\tools\\code_context_manager.py\n",
      "Analyzed: c:\\mygit\\compuse\\computer_use_demo\\tools\\collection.py\n",
      "Error analyzing c:\\mygit\\compuse\\computer_use_demo\\tools\\computer.py: 2 validation errors for ClassInfo\n",
      "class_variables.COMPUTER\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_type\n",
      "class_variables.API\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_type\n",
      "Error analyzing c:\\mygit\\compuse\\computer_use_demo\\tools\\edit.py: 1 validation error for ClassInfo\n",
      "class_variables.description\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_type\n",
      "Error analyzing c:\\mygit\\compuse\\computer_use_demo\\tools\\example_tool.py: 'in <string>' requires string as left operand, not type\n",
      "Analyzed: c:\\mygit\\compuse\\computer_use_demo\\tools\\expert.py\n",
      "Error analyzing c:\\mygit\\compuse\\computer_use_demo\\tools\\gotourl_reports.py: 2 validation errors for ClassInfo\n",
      "class_variables.COMPUTER\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_type\n",
      "class_variables.API\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_type\n",
      "Analyzed: c:\\mygit\\compuse\\computer_use_demo\\tools\\playwright.py\n",
      "Analyzed: c:\\mygit\\compuse\\computer_use_demo\\tools\\run.py\n",
      "Analyzed: c:\\mygit\\compuse\\computer_use_demo\\tools\\windows_navigation.py\n",
      "Analyzed: c:\\mygit\\compuse\\computer_use_demo\\tools\\__init__.py\n",
      "\n",
      "Analysis complete:\n",
      "Files processed: 8\n",
      "Classes found: 8\n",
      "Functions found: 10\n",
      "\n",
      "Classes:\n",
      "                                            filepath                   name  \\\n",
      "0  c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...           _BashSession   \n",
      "1  c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...               BashTool   \n",
      "2  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...               CodeFile   \n",
      "3  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...     CodeContextManager   \n",
      "4  c:\\mygit\\compuse\\computer_use_demo\\tools\\colle...         ToolCollection   \n",
      "5  c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...   GetExpertOpinionTool   \n",
      "6  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...       WebNavigatorTool   \n",
      "7  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...  WindowsNavigationTool   \n",
      "\n",
      "                                           docstring  methods_count  \\\n",
      "0                         A session of a bash shell.              2   \n",
      "1  A tool that allows the agent to run bash comma...              2   \n",
      "2                                               None              1   \n",
      "3                                               None             10   \n",
      "4           A collection of anthropic-defined tools.              2   \n",
      "5  A tool takes a detailed description of the pro...              1   \n",
      "6  A versatile tool that uses Playwright to inter...              5   \n",
      "7  A tool specializing in navigating Windows and ...              4   \n",
      "\n",
      "          base_classes  variables_count  \\\n",
      "0                   []                6   \n",
      "1  [BaseAnthropicTool]                3   \n",
      "2                   []                6   \n",
      "3                   []                0   \n",
      "4                   []                0   \n",
      "5  [BaseAnthropicTool]                3   \n",
      "6                   []                3   \n",
      "7                   []                3   \n",
      "\n",
      "                                             methods  has_docstring  \n",
      "0                                   [__init__, stop]           True  \n",
      "1                              [__init__, to_params]           True  \n",
      "2                                       [to_message]          False  \n",
      "3  [__init__, update_file, get_context_messages, ...          False  \n",
      "4                              [__init__, to_params]           True  \n",
      "5                                        [to_params]           True  \n",
      "6  [__init__, to_params, _create_structured_conte...           True  \n",
      "7  [__init__, _load_shortcuts, to_params, get_ses...           True  \n",
      "\n",
      "Dependencies:\n",
      "                                             filepath          dependency  \\\n",
      "0   c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...             asyncio   \n",
      "1   c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...                  os   \n",
      "2   c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...              typing   \n",
      "3   c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...           anthropic   \n",
      "4   c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...                base   \n",
      "5   c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...                  os   \n",
      "6   c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...                json   \n",
      "7   c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...                  re   \n",
      "8   c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...                 ast   \n",
      "9   c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...          subprocess   \n",
      "10  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...         dataclasses   \n",
      "11  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...            datetime   \n",
      "12  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...              typing   \n",
      "13  c:\\mygit\\compuse\\computer_use_demo\\tools\\colle...              typing   \n",
      "14  c:\\mygit\\compuse\\computer_use_demo\\tools\\colle...                json   \n",
      "15  c:\\mygit\\compuse\\computer_use_demo\\tools\\colle...           anthropic   \n",
      "16  c:\\mygit\\compuse\\computer_use_demo\\tools\\colle...            icecream   \n",
      "17  c:\\mygit\\compuse\\computer_use_demo\\tools\\colle...                base   \n",
      "18  c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...              openai   \n",
      "19  c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...              dotenv   \n",
      "20  c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...            icecream   \n",
      "21  c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...              typing   \n",
      "22  c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...                base   \n",
      "23  c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...                rich   \n",
      "24  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...                  os   \n",
      "25  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...             logging   \n",
      "26  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...          playwright   \n",
      "27  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...              typing   \n",
      "28  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...            requests   \n",
      "29  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...                 bs4   \n",
      "30  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...                  re   \n",
      "31  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...                base   \n",
      "32    c:\\mygit\\compuse\\computer_use_demo\\tools\\run.py             asyncio   \n",
      "33  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...           pyautogui   \n",
      "34  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...                time   \n",
      "35  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...              typing   \n",
      "36  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...             pathlib   \n",
      "37  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...                json   \n",
      "38  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...             logging   \n",
      "39  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...                base   \n",
      "40  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...                rich   \n",
      "41  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...                base   \n",
      "42  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...                bash   \n",
      "43  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...            computer   \n",
      "44  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...                edit   \n",
      "45  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...          collection   \n",
      "46  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...              expert   \n",
      "47  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...          playwright   \n",
      "48  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...     gotourl_reports   \n",
      "49  c:\\mygit\\compuse\\computer_use_demo\\tools\\__ini...  windows_navigation   \n",
      "\n",
      "   version  is_standard_lib  is_local  \n",
      "0     None            False     False  \n",
      "1     None             True     False  \n",
      "2     None             True     False  \n",
      "3   0.39.0            False     False  \n",
      "4     None            False      True  \n",
      "5     None             True     False  \n",
      "6     None            False     False  \n",
      "7     None            False     False  \n",
      "8     None             True     False  \n",
      "9     None             True     False  \n",
      "10    None             True     False  \n",
      "11    None             True     False  \n",
      "12    None             True     False  \n",
      "13    None             True     False  \n",
      "14    None            False     False  \n",
      "15  0.39.0            False     False  \n",
      "16   2.1.3            False     False  \n",
      "17    None            False      True  \n",
      "18  1.54.3            False     False  \n",
      "19    None            False     False  \n",
      "20   2.1.3            False     False  \n",
      "21    None             True     False  \n",
      "22    None            False      True  \n",
      "23  13.9.4            False     False  \n",
      "24    None             True     False  \n",
      "25    None            False     False  \n",
      "26    None            False      True  \n",
      "27    None             True     False  \n",
      "28  2.32.3            False     False  \n",
      "29   0.0.2            False     False  \n",
      "30    None            False     False  \n",
      "31    None            False      True  \n",
      "32    None            False     False  \n",
      "33  0.9.54            False     False  \n",
      "34    None            False     False  \n",
      "35    None             True     False  \n",
      "36    None             True     False  \n",
      "37    None            False     False  \n",
      "38    None            False     False  \n",
      "39    None            False      True  \n",
      "40  13.9.4            False     False  \n",
      "41    None            False      True  \n",
      "42    None            False      True  \n",
      "43    None            False      True  \n",
      "44    None            False      True  \n",
      "45    None            False      True  \n",
      "46    None            False      True  \n",
      "47    None            False      True  \n",
      "48    None            False      True  \n",
      "49    None            False      True  \n",
      "\n",
      "Classes missing documentation:\n",
      "                 name                                           filepath\n",
      "2            CodeFile  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...\n",
      "3  CodeContextManager  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...\n",
      "\n",
      "Project Statistics:\n",
      "Total Files: 8\n",
      "Total Classes: 8\n",
      "Total Functions: 10\n"
     ]
    }
   ],
   "source": [
    "# Initialize and analyze\n",
    "code_root = Path(code_root)\n",
    "analyzer = CodeAnalyzer(code_root=code_root)\n",
    "analyzer.analyze_repo()\n",
    "\n",
    "# Get DataFrames\n",
    "dfs = analyzer.to_dataframe()\n",
    "\n",
    "# Show class information\n",
    "print(\"\\nClasses:\")\n",
    "if not dfs['classes'].empty:\n",
    "    print(dfs['classes'])\n",
    "else:\n",
    "    print(\"No classes found\")\n",
    "\n",
    "# Show dependencies\n",
    "print(\"\\nDependencies:\")\n",
    "if not dfs['dependencies'].empty:\n",
    "    print(dfs['dependencies'])\n",
    "else:\n",
    "    print(\"No dependencies found\")\n",
    "\n",
    "# Find classes with missing documentation\n",
    "if not dfs['classes'].empty and 'docstring' in dfs['classes'].columns:\n",
    "    classes_missing_docs = dfs['classes'][dfs['classes']['docstring'].isna()]\n",
    "    print(\"\\nClasses missing documentation:\")\n",
    "    print(classes_missing_docs[['name', 'filepath']])\n",
    "else:\n",
    "    print(\"\\nNo classes to check for documentation\")\n",
    "\n",
    "# Get statistics\n",
    "print(\"\\nProject Statistics:\")\n",
    "print(f\"Total Files: {len(analyzer.files)}\")\n",
    "print(f\"Total Classes: {len(dfs['classes']) if not dfs['classes'].empty else 0}\")\n",
    "print(f\"Total Functions: {len(dfs['functions']) if not dfs['functions'].empty else 0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>name</th>\n",
       "      <th>docstring</th>\n",
       "      <th>methods_count</th>\n",
       "      <th>base_classes</th>\n",
       "      <th>variables_count</th>\n",
       "      <th>methods</th>\n",
       "      <th>has_docstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...</td>\n",
       "      <td>_BashSession</td>\n",
       "      <td>A session of a bash shell.</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>[__init__, stop]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...</td>\n",
       "      <td>BashTool</td>\n",
       "      <td>A tool that allows the agent to run bash comma...</td>\n",
       "      <td>2</td>\n",
       "      <td>[BaseAnthropicTool]</td>\n",
       "      <td>3</td>\n",
       "      <td>[__init__, to_params]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...</td>\n",
       "      <td>CodeFile</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>[to_message]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...</td>\n",
       "      <td>CodeContextManager</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[__init__, update_file, get_context_messages, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\mygit\\compuse\\computer_use_demo\\tools\\colle...</td>\n",
       "      <td>ToolCollection</td>\n",
       "      <td>A collection of anthropic-defined tools.</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[__init__, to_params]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...</td>\n",
       "      <td>GetExpertOpinionTool</td>\n",
       "      <td>A tool takes a detailed description of the pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>[BaseAnthropicTool]</td>\n",
       "      <td>3</td>\n",
       "      <td>[to_params]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...</td>\n",
       "      <td>WebNavigatorTool</td>\n",
       "      <td>A versatile tool that uses Playwright to inter...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>[__init__, to_params, _create_structured_conte...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...</td>\n",
       "      <td>WindowsNavigationTool</td>\n",
       "      <td>A tool specializing in navigating Windows and ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>[__init__, _load_shortcuts, to_params, get_ses...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath                   name  \\\n",
       "0  c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...           _BashSession   \n",
       "1  c:\\mygit\\compuse\\computer_use_demo\\tools\\bash_...               BashTool   \n",
       "2  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...               CodeFile   \n",
       "3  c:\\mygit\\compuse\\computer_use_demo\\tools\\code_...     CodeContextManager   \n",
       "4  c:\\mygit\\compuse\\computer_use_demo\\tools\\colle...         ToolCollection   \n",
       "5  c:\\mygit\\compuse\\computer_use_demo\\tools\\exper...   GetExpertOpinionTool   \n",
       "6  c:\\mygit\\compuse\\computer_use_demo\\tools\\playw...       WebNavigatorTool   \n",
       "7  c:\\mygit\\compuse\\computer_use_demo\\tools\\windo...  WindowsNavigationTool   \n",
       "\n",
       "                                           docstring  methods_count  \\\n",
       "0                         A session of a bash shell.              2   \n",
       "1  A tool that allows the agent to run bash comma...              2   \n",
       "2                                               None              1   \n",
       "3                                               None             10   \n",
       "4           A collection of anthropic-defined tools.              2   \n",
       "5  A tool takes a detailed description of the pro...              1   \n",
       "6  A versatile tool that uses Playwright to inter...              5   \n",
       "7  A tool specializing in navigating Windows and ...              4   \n",
       "\n",
       "          base_classes  variables_count  \\\n",
       "0                   []                6   \n",
       "1  [BaseAnthropicTool]                3   \n",
       "2                   []                6   \n",
       "3                   []                0   \n",
       "4                   []                0   \n",
       "5  [BaseAnthropicTool]                3   \n",
       "6                   []                3   \n",
       "7                   []                3   \n",
       "\n",
       "                                             methods  has_docstring  \n",
       "0                                   [__init__, stop]           True  \n",
       "1                              [__init__, to_params]           True  \n",
       "2                                       [to_message]          False  \n",
       "3  [__init__, update_file, get_context_messages, ...          False  \n",
       "4                              [__init__, to_params]           True  \n",
       "5                                        [to_params]           True  \n",
       "6  [__init__, to_params, _create_structured_conte...           True  \n",
       "7  [__init__, _load_shortcuts, to_params, get_ses...           True  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analyzer.to_dataframe()\n",
    "df['classes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "\n",
    "  model=\"nousresearch/hermes-3-llama-3.1-405b:free\",\n",
    "  messages=[{\"content\":  \"\"\"The following app description is partially complete in the \n",
    "                           directory c:/repo/dish_tracker \n",
    "              \n",
    "                           \n",
    "              \n",
    "                           There have been many additional features added to the html, but \n",
    "                           they are not all fully implemented.\n",
    "              \n",
    "                           \n",
    "              \n",
    "                           Your job is to complete the app.\n",
    "              \n",
    "                           \n",
    "              \n",
    "                           First, take a look at a journal of the steps taken to create the \n",
    "                           app, in the file \n",
    "                           C:\\\\mygit\\\\compuse\\\\computer_use_demo\\\\journal\\\\journal.log\n",
    "              \n",
    "                           \n",
    "              \n",
    "                           The biggest issue us that I can no longer save any new entries.\n",
    "              \n",
    "                           \n",
    "              \n",
    "                           Remove the Login functionality, If we decide to implement it it \n",
    "                           will be much later in the future.  \n",
    "              \n",
    "                           \n",
    "              \n",
    "                           If you have any questions, instead of asking the user,please get \n",
    "                           an expert opinion.\n",
    "              \n",
    "                               When you are done, please test the app to make sure it \n",
    "                           works. If it or any feature of it is not working, please fix \n",
    "                           it.\n",
    "              \n",
    "                           \n",
    "              \n",
    "                           If you finish and it is all working, please ask for an expert \n",
    "                           opinion on additional features you could add.\n",
    "              \n",
    "                           \n",
    "              \n",
    "                           \n",
    "              \n",
    "                           ## Create a web app that stores, updates and tracks the \n",
    "                           following information in a visual appealing and easy to edit \n",
    "                           way\n",
    "              \n",
    "                           \n",
    "              \n",
    "                           It is used to track the status of Dish Machine Sales and \n",
    "                           Installations.\n",
    "              \n",
    "                           The following info should be stored and displayed:\n",
    "              \n",
    "                               - Priority of Install (1-5)\n",
    "              \n",
    "                               - Salesperson Name\n",
    "              \n",
    "                               - Name of Customer\n",
    "              \n",
    "                               - Machine Model (Drop Down with the ability to add new \n",
    "                           models((A4, A5, D2, UC34, A6)))\n",
    "              \n",
    "                               - Have Verbal Commit (Date or None)\n",
    "              \n",
    "                               - Have Paperwork? (Date or None)\n",
    "              \n",
    "                               - Have Money?? (Date or None)\n",
    "              \n",
    "                               - Installed (Date or None)\n",
    "              \n",
    "                               - Status (Drop Down with options: Pending Salesperson, \n",
    "                           Pending Machine, Pending Customer, Complete)\n",
    "              \n",
    "                               - Notes\n",
    "              \n",
    "                           \n",
    "              \n",
    "                           The app should have the following features:\n",
    "              \n",
    "                               - Add new entries\n",
    "              \n",
    "                               - Edit existing entries\n",
    "              \n",
    "                               - Delete entries\n",
    "              \n",
    "                               - Sort by Priority, Salesperson, Customer, Model, Status\n",
    "              \n",
    "                               - Filter by Status, Salesperson\n",
    "              \n",
    "                               - Search by Customer, Salesperson, Model, Status\n",
    "              \n",
    "                               - Export to Excel\n",
    "              \n",
    "                           Other features for ease of use or visual appeal are welcome.\"\"\",\n",
    "                \"role\": \"user\"}]\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "print(OPENROUTER_API_KEY)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
